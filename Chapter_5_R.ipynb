{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_5.R",
      "provenance": [],
      "authorship_tag": "ABX9TyPfkfpwfVNlhouhdUqSv+G9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolinacasanova/Chapter_5/blob/master/Chapter_5_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUk15okD91WF",
        "colab_type": "text"
      },
      "source": [
        "Chapter 5: Classification using Decision Trees and Rules\n",
        "\n",
        "This chapter focuses on two machine learning classification methods decision trees and rule learners. Both mothods help to make complex decisions from sets of simple choices, by dividing data into segments. \n",
        "\n",
        "A decision tree is one possibility to display an algorithm which contains conditional control statements. In a decision tree the relationship among different features and potential outcomes is presented and choices help to split data across the branches to finally indicate the potential outcome. It helps to go from the observations in the branches to the tree to the concludsions which are presented in the leaves. Decision trees are based on the heuristic recursive partioning, also known as divide and conquer. The data is split into subsets and this is repeated until the process stops when the data within the subset is enough homogenous. \n",
        "\n"
      ]
    }
  ]
}