{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_5.R",
      "provenance": [],
      "authorship_tag": "ABX9TyN4P4E9nFc0YjApb2aE4OJH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolinacasanova/Chapter_5/blob/master/Chapter_5_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUk15okD91WF",
        "colab_type": "text"
      },
      "source": [
        "Chapter 5: Classification using Decision Trees and Rules\n",
        "\n",
        "This chapter focuses on two machine learning classification methods decision trees and rule learners. Both mothods help to make complex decisions from sets of simple choices, by dividing data into segments. \n",
        "\n",
        "A decision tree is one possibility to display an algorithm which contains conditional control statements. In a decision tree the relationship among different features and potential outcomes is presented and choices help to split data across the branches to finally indicate the potential outcome. It helps to go from the observations in the branches to the tree to the concludsions which are presented in the leaves. Decision trees are based on the heuristic recursive partioning, also known as divide and conquer. The data is split into subsets and this is repeated until the process stops when the data within the subset is enough homogenous. \n",
        "\n",
        "PART 1- Decision Trees\n",
        "In order to use a decision tree, first of all the feature which will be used to split the data has to be defined. When splitting the data, the goal is to achieve purity. Purity means that the subset of examples contains only single class. A very often measure of purity is entropy. This measurement quantifies the randomness and disorder within a set of class values. When entropy is high, this means that the set is very diverse and there is only littlecommonality apparent. Therefore, the goal is to find a feature for the split which reduces entropy and this way the homogeneity within a group can be increased. \n",
        "\n",
        "In the first example entropy will be calculated for data which is divided into two classes. The red class contains 60% of the data and 40% of the data is in the white class. Entropy can be calculated the following way.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azSab-jzgaUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "-60*log2(0.6)-0.4*log2(0.4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9NWxMq4gk9h",
        "colab_type": "text"
      },
      "source": [
        "For this example, entropy is 0.9709506. Entropy is measured in bits and for only tow possible classes the resulting values can range from 0 to 1. In this example entropy is very high and it can be concluded that the data is very diverse and little plurality among the group members can be observed. \n",
        "\n",
        "Entropy can also be analyzed by means of a plot. Using the curve () function, entropy can be visualized and plotted. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzaqMUGihRXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "curve(-x*log2(x)-(1-x)*log2(1-x), \n",
        "  col= \"red\", xlab=\"x\", ylab=\"Entropy\", lwd=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TvYc8Juhmda",
        "colab_type": "text"
      },
      "source": [
        "By this visualization it can be observed that entropy achieves the peak at x=50%, as this example contains a two-class arrangement. This changes when one class dominates the other. \n",
        "\n",
        "EXAMPLE 1\n",
        "A good example to show how machine learning is used in practice is for identifying risky loans. Decision trees can help in such a case to formulate a statistical model. Based on this model, a loan application will be approved or rejected. Such an automated credit scoring model can then for example be used for immediate online approval processes. "
      ]
    }
  ]
}