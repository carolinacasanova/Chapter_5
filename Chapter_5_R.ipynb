{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_5.R",
      "provenance": [],
      "authorship_tag": "ABX9TyPmbt1sVjX0koug5hV+e7Ri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolinacasanova/Chapter_5/blob/master/Chapter_5_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUk15okD91WF",
        "colab_type": "text"
      },
      "source": [
        "Chapter 5: Classification using Decision Trees and Rules\n",
        "\n",
        "This chapter focuses on two machine learning classification methods decision trees and rule learners. Both mothods help to make complex decisions from sets of simple choices, by dividing data into segments. \n",
        "\n",
        "A decision tree is one possibility to display an algorithm which contains conditional control statements. In a decision tree the relationship among different features and potential outcomes is presented and choices help to split data across the branches to finally indicate the potential outcome. It helps to go from the observations in the branches to the tree to the concludsions which are presented in the leaves. Decision trees are based on the heuristic recursive partioning, also known as divide and conquer. The data is split into subsets and this is repeated until the process stops when the data within the subset is enough homogenous. \n",
        "\n",
        "Part 1: Decision Trees\n",
        "In order to use a decision tree, first of all the feature which will be used to split the data has to be defined. When splitting the data, the goal is to achieve purity. Purity means that the subset of examples contains only single class. A very often measure of purity is entropy. This measurement quantifies the randomness and disorder within a set of class values. When entropy is high, this means that the set is very diverse and there is only littlecommonality apparent. Therefore, the goal is to find a feature for the split which reduces entropy and this way the homogeneity within a group can be increased. \n"
      ]
    }
  ]
}